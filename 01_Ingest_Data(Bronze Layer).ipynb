{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ba31e013-87ec-474b-8557-b3588ca5fe30",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##  Project Objective\n",
    "The objective of this data engineering project is to build a scalable, end-to-end data pipeline that ingests, processes, and enriches Bitcoin’s daily market data. This pipeline will serve as the foundation for analytical reporting, time-series feature engineering, and predictive modeling related to Bitcoin's market behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e155c94f-3cb1-4eac-b88d-1b37c63c220d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Benefits\n",
    "A Bitcoin investment advisory firm\n",
    "- The advisory team can trust the data for research, reports, and investor recommendations without manual wrangling or risk of errors.\n",
    "- Helps the firm detect trends, shifts, and patterns in the Bitcoin market — empowering analysts to make better buy/sell/hold calls.\n",
    "- Enables risk analysts to flag abnormal behavior early, protecting clients and improving the firm's credibility.\n",
    "- Enhances the firm’s client reporting and supports data-driven decision-making.\n",
    "- Reduces operational overhead, freeing up analysts to focus on strategy instead of data prep."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "08491843-5724-4a5b-a6b4-b8f16b3e2323",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##  Description\n",
    "This notebook handles the ingestion of raw Bitcoin daily market data. It reads the dataset from a CSV source, infers schema, performs initial inspection, and writes the output to a raw (bronze) layer for further processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2b8e0b96-9dee-490d-b949-683a791bf468",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##  Tools & Technologies Used in This Notebook\n",
    "| Tool / Library | Purpose |\n",
    "|----------------|---------|\n",
    "| **Apache Spark (PySpark)** | Distributed data processing for ingesting and handling large datasets |\n",
    "| **Databricks / Jupyter Notebook** | Interactive environment for writing and testing code |\n",
    "| **Delta Lake / Parquet** | Optimized storage format for raw (bronze) layer |\n",
    "| **DBFS or Cloud Storage (e.g., `/mnt/raw/`)** | Storage location for input dataset |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e6402cc-7dad-418b-b189-ab0ab69e040a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>dbfs:/Volumes/bitcoin/market_data/coin/Bitcoin_history_data.csv</td><td>Bitcoin_history_data.csv</td><td>335981</td><td>1753691038000</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "dbfs:/Volumes/bitcoin/market_data/coin/Bitcoin_history_data.csv",
         "Bitcoin_history_data.csv",
         335981,
         1753691038000
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "path",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "size",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "modificationTime",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%fs ls /Volumes/bitcoin/market_data/coin/Bitcoin_history_data.csv    # List the contents of the specified directory in DBFS (Databricks File System)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e8e54dc-0b5a-416f-8759-6640816e378b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- Date: date (nullable = true)\n |-- Close: double (nullable = true)\n |-- High: double (nullable = true)\n |-- Low: double (nullable = true)\n |-- Open: double (nullable = true)\n |-- Volume: long (nullable = true)\n\n+----------+------------------+------------------+------------------+-----------------+--------+\n|      Date|             Close|              High|               Low|             Open|  Volume|\n+----------+------------------+------------------+------------------+-----------------+--------+\n|2014-09-17| 457.3340148925781|468.17401123046875| 452.4219970703125| 465.864013671875|21056800|\n|2014-09-18|424.44000244140625| 456.8599853515625|   413.10400390625|456.8599853515625|34483200|\n|2014-09-19| 394.7959899902344| 427.8349914550781| 384.5320129394531|424.1029968261719|37919700|\n|2014-09-20|408.90399169921875| 423.2959899902344|389.88299560546875|394.6730041503906|36863600|\n|2014-09-21| 398.8210144042969| 412.4259948730469| 393.1809997558594|408.0849914550781|26580100|\n+----------+------------------+------------------+------------------+-----------------+--------+\nonly showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# Read the Bitcoin history CSV file into a Spark DataFrame\n",
    "# - header=True: uses the first row as column names\n",
    "# - inferSchema=True: automatically infers data types for each column\n",
    "df_raw = spark.read.csv(\"/Volumes/bitcoin/market_data/coin/Bitcoin_history_data.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Display the schema of the DataFrame to understand the structure and data types\n",
    "df_raw.printSchema()\n",
    "\n",
    "# Show the first 5 rows of the DataFrame for a quick preview of the data\n",
    "df_raw.show(5)\n",
    "\n",
    "# Write the raw DataFrame to a Delta Lake table in the 'bronze' layer\n",
    "# - format(\"delta\"): saves the data in Delta format for ACID transactions and versioning\n",
    "# - mode(\"overwrite\"): replaces any existing data in the target table\n",
    "# - saveAsTable(): registers the table in the metastore under the specified name\n",
    "df_raw.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .saveAsTable(\"bitcoin.market_data.bronze_bitcoin\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6740942322275570,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "01_Ingest_Data(Bronze Layer)",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}