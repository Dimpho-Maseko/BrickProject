{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ba31e013-87ec-474b-8557-b3588ca5fe30",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##  Project Objective\n",
    "The objective of this data engineering project is to build a scalable, end-to-end data pipeline that ingests, processes, and enriches Bitcoin’s daily market data. This pipeline will serve as the foundation for analytical reporting, time-series feature engineering, and predictive modeling related to Bitcoin's market behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e155c94f-3cb1-4eac-b88d-1b37c63c220d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Benefits\n",
    "A Bitcoin investment advisory firm\n",
    "- The advisory team can trust the data for research, reports, and investor recommendations without manual wrangling or risk of errors.\n",
    "- Helps the firm detect trends, shifts, and patterns in the Bitcoin market — empowering analysts to make better buy/sell/hold calls.\n",
    "- Enables risk analysts to flag abnormal behavior early, protecting clients and improving the firm's credibility.\n",
    "- Enhances the firm’s client reporting and supports data-driven decision-making.\n",
    "- Reduces operational overhead, freeing up analysts to focus on strategy instead of data prep."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "08491843-5724-4a5b-a6b4-b8f16b3e2323",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##  Description\n",
    "This notebook handles the ingestion of raw Bitcoin daily market data. It reads the dataset from a CSV source, infers schema, performs initial inspection, and writes the output to a raw (bronze) layer for further processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2b8e0b96-9dee-490d-b949-683a791bf468",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##  Tools & Technologies Used in This Notebook\n",
    "| Tool / Library | Purpose |\n",
    "|----------------|---------|\n",
    "| **Apache Spark (PySpark)** | Distributed data processing for ingesting and handling large datasets |\n",
    "| **Databricks / Jupyter Notebook** | Interactive environment for writing and testing code |\n",
    "| **Delta Lake / Parquet** | Optimized storage format for raw (bronze) layer |\n",
    "| **DBFS or Cloud Storage (e.g., `/mnt/raw/`)** | Storage location for input dataset |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e6402cc-7dad-418b-b189-ab0ab69e040a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>dbfs:/Volumes/bitcoin/market_data/coin/Bitcoin_history_data.csv</td><td>Bitcoin_history_data.csv</td><td>335981</td><td>1753691038000</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "dbfs:/Volumes/bitcoin/market_data/coin/Bitcoin_history_data.csv",
         "Bitcoin_history_data.csv",
         335981,
         1753691038000
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "path",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "size",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "modificationTime",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#%fs ls /Volumes/bitcoin/market_data/coin/Bitcoin_history_data.csv    # List the contents of the specified directory in DBFS (Databricks File System)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d08619c5-1c96-4c5d-8d6d-491a8d43fd72",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read the Bitcoin history CSV file into a Spark DataFrame\n",
    "# - header=True: uses the first row as column names\n",
    "# - inferSchema=True: automatically infers data types for each column\n",
    "df_raw = spark.read.csv(\"/Volumes/bitcoin/market_data/coin/Bitcoin_history_data.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Display the schema of the DataFrame to understand the structure and data types\n",
    "df_raw.printSchema()\n",
    "\n",
    "# Show the first 5 rows of the DataFrame for a quick preview of the data\n",
    "df_raw.show(5)\n",
    "\n",
    "# Write the raw DataFrame to a Delta Lake table in the 'bronze' layer\n",
    "# - format(\"delta\"): saves the data in Delta format for ACID transactions and versioning\n",
    "# - mode(\"overwrite\"): replaces any existing data in the target table\n",
    "# - saveAsTable(): registers the table in the metastore under the specified name\n",
    "df_raw.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .saveAsTable(\"bitcoin.market_data.bronze_bitcoin\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e8e54dc-0b5a-416f-8759-6640816e378b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "    <html>\n",
       "      <div style=\"font-size:18px\">\n",
       "        The Delta Live Tables (DLT) module is not supported on this cluster.\n",
       "        You should either <a href=\"?o=2108449739687857#joblist/pipelines/create?initialSource=%2FUsers%2Fmasekodimpho2001%40gmail.com%2F01_Ingest_Data%28Bronze+Layer%29&redirectNotebookId=3383454720836287\">create a new pipeline</a> or use an existing pipeline to run DLT code.\n",
       "      </div>\n",
       "    </html>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "    <html>\n",
       "      <div style=\"font-size:18px\">\n",
       "        The Delta Live Tables (DLT) module is not supported on this cluster.\n",
       "        You should either <a href=\"?o=2108449739687857#joblist/pipelines/create?initialSource=%2FUsers%2Fmasekodimpho2001%40gmail.com%2F01_Ingest_Data%28Bronze+Layer%29&redirectNotebookId=3383454720836287\">create a new pipeline</a> or use an existing pipeline to run DLT code.\n",
       "      </div>\n",
       "    </html>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-6740942322275571>, line 1\u001B[0m\n",
       "\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mdlt\u001B[39;00m\n",
       "\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpyspark\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msql\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfunctions\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n",
       "\u001B[1;32m      4\u001B[0m \u001B[38;5;129m@dlt\u001B[39m\u001B[38;5;241m.\u001B[39mtable(\n",
       "\u001B[1;32m      5\u001B[0m     name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbronze_bitcoin\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n",
       "\u001B[1;32m      6\u001B[0m     comment\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRaw Bitcoin historical data ingested from CSV into the bronze layer\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m      7\u001B[0m )\n",
       "\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mingest_bitcoin_data\u001B[39m():\n",
       "\u001B[1;32m      9\u001B[0m     \u001B[38;5;66;03m# Read the Bitcoin CSV file from DBFS\u001B[39;00m\n",
       "\n",
       "File \u001B[0;32m/databricks/python_shell/lib/dbruntime/autoreload/discoverability/hook.py:71\u001B[0m, in \u001B[0;36mAutoreloadDiscoverabilityHook._patched_import\u001B[0;34m(self, name, *args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m     65\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_should_hint \u001B[38;5;129;01mand\u001B[39;00m (\n",
       "\u001B[1;32m     66\u001B[0m     (module \u001B[38;5;241m:=\u001B[39m sys\u001B[38;5;241m.\u001B[39mmodules\u001B[38;5;241m.\u001B[39mget(absolute_name)) \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m\n",
       "\u001B[1;32m     67\u001B[0m     (fname \u001B[38;5;241m:=\u001B[39m get_allowed_file_name_or_none(module)) \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m\n",
       "\u001B[1;32m     68\u001B[0m     (mtime \u001B[38;5;241m:=\u001B[39m os\u001B[38;5;241m.\u001B[39mstat(fname)\u001B[38;5;241m.\u001B[39mst_mtime) \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlast_mtime_by_modname\u001B[38;5;241m.\u001B[39mget(\n",
       "\u001B[1;32m     69\u001B[0m         absolute_name, \u001B[38;5;28mfloat\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minf\u001B[39m\u001B[38;5;124m\"\u001B[39m)) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_should_hint):\n",
       "\u001B[1;32m     70\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_should_hint \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
       "\u001B[0;32m---> 71\u001B[0m module \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_original_builtins_import(name, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
       "\u001B[1;32m     72\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (fname \u001B[38;5;241m:=\u001B[39m fname \u001B[38;5;129;01mor\u001B[39;00m get_allowed_file_name_or_none(module)) \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
       "\u001B[1;32m     73\u001B[0m     mtime \u001B[38;5;241m=\u001B[39m mtime \u001B[38;5;129;01mor\u001B[39;00m os\u001B[38;5;241m.\u001B[39mstat(fname)\u001B[38;5;241m.\u001B[39mst_mtime\n",
       "\n",
       "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'dlt'"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "ModuleNotFoundError",
        "evalue": "No module named 'dlt'"
       },
       "metadata": {
        "errorSummary": "<span class='ansi-red-fg'>ModuleNotFoundError</span>: No module named 'dlt'"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
        "File \u001B[0;32m<command-6740942322275571>, line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mdlt\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpyspark\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msql\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfunctions\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;129m@dlt\u001B[39m\u001B[38;5;241m.\u001B[39mtable(\n\u001B[1;32m      5\u001B[0m     name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbronze_bitcoin\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m      6\u001B[0m     comment\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRaw Bitcoin historical data ingested from CSV into the bronze layer\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m      7\u001B[0m )\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mingest_bitcoin_data\u001B[39m():\n\u001B[1;32m      9\u001B[0m     \u001B[38;5;66;03m# Read the Bitcoin CSV file from DBFS\u001B[39;00m\n",
        "File \u001B[0;32m/databricks/python_shell/lib/dbruntime/autoreload/discoverability/hook.py:71\u001B[0m, in \u001B[0;36mAutoreloadDiscoverabilityHook._patched_import\u001B[0;34m(self, name, *args, **kwargs)\u001B[0m\n\u001B[1;32m     65\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_should_hint \u001B[38;5;129;01mand\u001B[39;00m (\n\u001B[1;32m     66\u001B[0m     (module \u001B[38;5;241m:=\u001B[39m sys\u001B[38;5;241m.\u001B[39mmodules\u001B[38;5;241m.\u001B[39mget(absolute_name)) \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m\n\u001B[1;32m     67\u001B[0m     (fname \u001B[38;5;241m:=\u001B[39m get_allowed_file_name_or_none(module)) \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m\n\u001B[1;32m     68\u001B[0m     (mtime \u001B[38;5;241m:=\u001B[39m os\u001B[38;5;241m.\u001B[39mstat(fname)\u001B[38;5;241m.\u001B[39mst_mtime) \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlast_mtime_by_modname\u001B[38;5;241m.\u001B[39mget(\n\u001B[1;32m     69\u001B[0m         absolute_name, \u001B[38;5;28mfloat\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minf\u001B[39m\u001B[38;5;124m\"\u001B[39m)) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_should_hint):\n\u001B[1;32m     70\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_should_hint \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m---> 71\u001B[0m module \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_original_builtins_import(name, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m     72\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (fname \u001B[38;5;241m:=\u001B[39m fname \u001B[38;5;129;01mor\u001B[39;00m get_allowed_file_name_or_none(module)) \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     73\u001B[0m     mtime \u001B[38;5;241m=\u001B[39m mtime \u001B[38;5;129;01mor\u001B[39;00m os\u001B[38;5;241m.\u001B[39mstat(fname)\u001B[38;5;241m.\u001B[39mst_mtime\n",
        "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'dlt'"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import dlt\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "@dlt.table(\n",
    "    name=\"bronze_bitcoin_historical\",\n",
    "    comment=\"Raw Bitcoin historical data ingested from CSV into the bronze layer\"\n",
    ")\n",
    "def ingest_bitcoin_data():\n",
    "    # Read the Bitcoin CSV file from DBFS\n",
    "    df_raw = spark.read.csv(\n",
    "        \"/Volumes/bitcoin/market_data/coin/Bitcoin_history_data.csv\",\n",
    "        header=True,\n",
    "        inferSchema=True\n",
    "    )\n",
    "    \n",
    "    return df_raw\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6740942322275570,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "01_Ingest_Data(Bronze Layer)",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}